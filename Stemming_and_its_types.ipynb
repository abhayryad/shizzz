{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPv4Hnsl3rq6/Dg8nQ5yS2L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhayryad/shizzz/blob/main/Stemming_and_its_types.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3aZ5zFZat55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bzI9e5_ahWD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b658add"
      },
      "source": [
        "## Stemming\n",
        "\n",
        "Stemming is a process in natural language processing (NLP) that reduces words to their root or base form, called a \"stem\". The goal is to group together words that have similar meanings but different endings (e.g., \"running\", \"runs\", and \"ran\" would all be reduced to the stem \"run\").\n",
        "\n",
        "**How it works:**\n",
        "\n",
        "Stemming typically works by removing suffixes from words based on a set of rules or algorithms. For example, a simple rule might be to remove \"ing\" if the word ends with \"ing\" and has at least one vowel before the \"ing\". More complex algorithms, like the Porter stemming algorithm, use multiple steps and rules to handle various suffixes and irregular words.\n",
        "\n",
        "**Why use stemming?**\n",
        "\n",
        "*   **Reduce vocabulary size:** By reducing words to their stems, you can significantly reduce the number of unique words in your dataset, which can be beneficial for tasks like text classification or information retrieval.\n",
        "*   **Improve search results:** When searching for information, stemming can help find relevant documents even if the query uses a different form of a word. For example, searching for \"running\" might also return documents containing \"run\" or \"ran\".\n",
        "\n",
        "**Limitations of stemming:**\n",
        "\n",
        "*   **Over-stemming:** Stemming can sometimes remove too much of a word, resulting in stems that are not actual words or that group together words with different meanings (e.g., \"universal\" and \"university\" might be stemmed to the same root).\n",
        "*   **Under-stemming:** Conversely, stemming might not remove enough of a word, failing to group together words that should be considered the same.\n",
        "*   **Doesn't consider context:** Stemming is a rule-based process that doesn't take into account the context of a word, which can lead to incorrect stemming in some cases.\n",
        "\n",
        "Due to its limitations, stemming is often used in conjunction with or replaced by **lemmatization**, which is a more sophisticated process that uses a dictionary and considers the part of speech of a word to reduce it to its base or dictionary form (lemma). Lemmatization generally produces better results but is also more computationally expensive."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Classification problem\n",
        "## comments of product is a psotive review or negative review\n",
        "## Reviews ---> eating, eat, eaten, [going, gone, goes]---->go"
      ],
      "metadata": {
        "id": "uGUZrulqbM15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7841ab94"
      },
      "source": [
        "## RegexpStemmer\n",
        "\n",
        "The `RegexpStemmer` is a simple stemming algorithm provided by the NLTK library in Python. It uses regular expressions to remove suffixes from words.\n",
        "\n",
        "**How it works:**\n",
        "\n",
        "You provide `RegexpStemmer` with a regular expression pattern. The stemmer then attempts to match this pattern at the end of a word and remove it if it matches. For example, you could use a regular expression like `ing$` to remove the \"ing\" suffix.\n",
        "\n",
        "**When to use it:**\n",
        "\n",
        "`RegexpStemmer` is useful when you have specific suffixes you want to remove and can define a regular expression to capture them. It's simpler and faster than more complex algorithms like Porter or Snowball, but it's also less comprehensive and may not handle irregular words or complex suffix combinations as well.\n",
        "\n",
        "**Limitations:**\n",
        "\n",
        "*   Requires knowledge of regular expressions.\n",
        "*   May over-stem or under-stem depending on the chosen pattern.\n",
        "*   Doesn't consider the context or part of speech of words.\n",
        "\n",
        "Here's an example of how to use `RegexpStemmer` in NLTK:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6035eeb",
        "outputId": "9570adfc-0f58-48f8-d810-4a79f496d283"
      },
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "\n",
        "stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "words = ['running', 'runs', 'runner', 'fairly', 'adjustable', 'good']\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(stemmed_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['runn', 'run', 'runner', 'fairly', 'adjust', 'good']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer=RegexpStemmer('ing$|s$|e$|able$',min=4)"
      ],
      "metadata": {
        "id": "XwKcUeZubIGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem('eating')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DuPvfRATd89E",
        "outputId": "4c7863c1-ece5-42e5-cce8-c2995c60a301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec30f803"
      },
      "source": [
        "## PorterStemmer\n",
        "\n",
        "The `PorterStemmer` is one of the most common and widely used stemming algorithms for English. It's an algorithmic stemmer that applies a series of rules to remove suffixes from words.\n",
        "\n",
        "**How it works:**\n",
        "\n",
        "The Porter stemming algorithm works in multiple steps, with each step applying a set of rules to transform the word. These rules are designed to handle various English suffixes in a specific order to produce the correct stem. The algorithm is deterministic, meaning it will always produce the same stem for a given word.\n",
        "\n",
        "**When to use it:**\n",
        "\n",
        "The `PorterStemmer` is a good general-purpose stemmer for English text. It's relatively efficient and has been widely tested. It's often used in information retrieval and text mining tasks.\n",
        "\n",
        "**Limitations:**\n",
        "\n",
        "*   **Not a dictionary-based stemmer:** It doesn't use a dictionary to check if the resulting stem is a valid word. This can sometimes lead to over-stemming or under-stemming.\n",
        "*   **Specific to English:** The rules are designed for English and may not work well for other languages.\n",
        "*   **Can be aggressive:** In some cases, it can be too aggressive in removing suffixes, leading to stems that are not intuitive.\n",
        "\n",
        "Here's an example of how to use `PorterStemmer` in NLTK:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f877d9d7",
        "outputId": "c347f6a0-3168-41a8-be05-a82477201e55"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "word_list = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmers\"]\n",
        "stemmed_words = [porter_stemmer.stem(word) for word in word_list]\n",
        "\n",
        "print(stemmed_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['program', 'program', 'programm', 'program', 'programm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XB_ITmTOcPJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ebd3567"
      },
      "source": [
        "## SnowballStemmer\n",
        "\n",
        "The `SnowballStemmer` is an improved version of the PorterStemmer and supports multiple languages. It is also known as Porter2 stemming algorithm.\n",
        "\n",
        "**How it works:**\n",
        "\n",
        "Similar to the PorterStemmer, the SnowballStemmer applies a series of rules to remove suffixes. However, it includes additional rules and is more aggressive in some cases. The key advantage is its support for various languages by specifying the language during initialization.\n",
        "\n",
        "**When to use it:**\n",
        "\n",
        "Use `SnowballStemmer` when you need a more aggressive stemmer than PorterStemmer or when working with text in languages other than English.\n",
        "\n",
        "**Limitations:**\n",
        "\n",
        "*   Like other algorithmic stemmers, it doesn't use a dictionary and may produce stems that are not valid words.\n",
        "*   Can be more aggressive than desired in some cases.\n",
        "\n",
        "Here's an example of how to use `SnowballStemmer` in NLTK for English:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "# Initialize SnowballStemmer for English\n",
        "snowball_stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "words_to_stem = [\"generous\", \"generation\", \"generously\", \"generate\"]\n",
        "stemmed_words = [snowball_stemmer.stem(word) for word in words_to_stem]\n",
        "\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "828hVjvhcO63",
        "outputId": "127c4253-0503-471c-d9ac-958a470df7f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['generous', 'generat', 'generous', 'generat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " stemmer.stem('fairly'),stemmer.stem('sportingly')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcRRKMnPe6qq",
        "outputId": "493fdec2-4805-43e1-daf5-d4cb3ab1c01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fairly', 'sportingly')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snowball_stemmer.stem('fairly'),snowball_stemmer.stem('sportingly')\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdy9HNMRfoO3",
        "outputId": "5a7ab87c-2974-4a47-f8f0-b0d5b3f10969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fair', 'sport')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snowball_stemmer.stem('goes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "73aBgCBNgi7d",
        "outputId": "5cc995ac-7032-4c2b-8461-42d349b426cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'goe'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}